{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "raw_dataset = pd.read_csv(\"../DATA/league_games.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alterando o conjunto de dados\n",
    "Como observado no notebook `initial-analysis.ipynb` o modelo _baseline_ apresentou taxa de acerto acima de 98%. Esse resultado sugere que a seleção das features (comparar os dados entre as equipes) não foi boa. Nesse sentido, decidimos remodelar o problema.\n",
    "\n",
    "O novo problema será _com base nos dados relacionados à equipe azul, vamos tentar prever o outcome da partida, ou seja, se a equipe azul ganhou ou não_. Com isso em mente, precisamos remover algumas features do conjunto anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['blue.win', 'blue.firstBlood', 'blue.firstTower', 'blue.firstInhibitor',\n",
       "       'blue.firstBaron', 'blue.firstDragon', 'blue.firstRiftHerald',\n",
       "       'blue.towerKills', 'blue.inhibitorKills', 'blue.baronKills',\n",
       "       'blue.dragonKills', 'blue.riftHeraldKills', 'red.win', 'red.firstBlood',\n",
       "       'red.firstTower', 'red.firstInhibitor', 'red.firstBaron',\n",
       "       'red.firstDragon', 'red.firstRiftHerald', 'red.towerKills',\n",
       "       'red.inhibitorKills', 'red.baronKills', 'red.dragonKills',\n",
       "       'red.riftHeraldKills', 'blue.kills', 'red.kills', 'blue.deaths',\n",
       "       'red.deaths', 'blue.assists', 'red.assists', 'blue.visionScore',\n",
       "       'red.visionScore', 'blue.csPerMin', 'red.csPerMin', 'blue.goldPerMin',\n",
       "       'red.goldPerMin', 'blue.crowdControlTime', 'red.crowdControlTime'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print all columns name\n",
    "display(raw_dataset.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['blue.win', 'blue.firstBlood', 'blue.firstTower', 'blue.firstInhibitor',\n",
       "       'blue.firstBaron', 'blue.firstDragon', 'blue.firstRiftHerald',\n",
       "       'blue.towerKills', 'blue.inhibitorKills', 'blue.baronKills',\n",
       "       'blue.dragonKills', 'blue.riftHeraldKills', 'blue.kills', 'blue.deaths',\n",
       "       'blue.assists', 'blue.visionScore', 'blue.csPerMin', 'blue.goldPerMin',\n",
       "       'blue.crowdControlTime'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a new dataset without red team information\n",
    "to_drop = [\n",
    "    'red.win', 'red.firstBlood', 'red.firstTower', 'red.firstInhibitor',\n",
    "    'red.firstBaron', 'red.firstDragon', 'red.firstRiftHerald', 'red.towerKills',\n",
    "    'red.inhibitorKills', 'red.baronKills', 'red.dragonKills', 'red.riftHeraldKills',\n",
    "    'red.kills', 'red.deaths', 'red.assists', 'red.visionScore', 'red.csPerMin',\n",
    "    'red.goldPerMin', 'red.crowdControlTime'\n",
    "]\n",
    "\n",
    "blue_dataset = raw_dataset.copy()\n",
    "blue_dataset.drop(to_drop, axis=1, inplace=True)\n",
    "\n",
    "display(blue_dataset.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "blue.win                   int64\n",
       "blue.firstBlood            int64\n",
       "blue.firstTower            int64\n",
       "blue.firstInhibitor        int64\n",
       "blue.firstBaron            int64\n",
       "blue.firstDragon           int64\n",
       "blue.firstRiftHerald       int64\n",
       "blue.towerKills            int64\n",
       "blue.inhibitorKills        int64\n",
       "blue.baronKills            int64\n",
       "blue.dragonKills           int64\n",
       "blue.riftHeraldKills       int64\n",
       "blue.kills                 int64\n",
       "blue.deaths                int64\n",
       "blue.assists               int64\n",
       "blue.visionScore           int64\n",
       "blue.csPerMin            float64\n",
       "blue.goldPerMin          float64\n",
       "blue.crowdControlTime      int64\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(16272, 19)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print more informations\n",
    "display(blue_dataset.dtypes, blue_dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Planejando a _baseline_\n",
    "O modelo _baseline_ servirá como um \"guia\" para mensurar a qualidade dos modelos mais sofisticados. A _baseline_, nesse caso, poderá nos informar sobre possíveis complexidades desnecessárias.\n",
    "\n",
    "Neste projeto, nossa _baseline_ será definida por uma Regressão Logística. Neste modelo, as probabilidades que descrevem os possíveis resultados de uma única tentativa são modeladas usando uma função logística. A implementação escolhida foi a `LogisticRegression` da biblioteca **scikit-learn**.\n",
    "\n",
    "Inicialmente iremos separar o conjunto `blue_dataset` em dois subconjuntos: treinamento e teste. Esse tipo de procedimento é importante para evitar o problema de _overfitting_. Usando a biblioteca scikit-learn podemos separar aleatoriamente o conjunto principal a partir da função auxiliar `train_test_split`. A separação será feita usando a relação 80/20, ou seja, 80% dos dados serão de treinamento e os 20% restantes serão de teste.\n",
    "\n",
    "Dentro do conjunto de treinamento, podemos utilizar o procedimento de validação. A seleção do conjunto de validação será feita utilizando o método de _cross-validation_ (CV) **stratified k-fold** com 10 _splits_ e 4 repetições (no scikit-learn, `RepeatedStratifiedKFold`). Os parâmetros testados para a Regressão Logística serão:\n",
    "- Com e sem regularização (usando penalidade `l2`);\n",
    "- Inverso do peso da regularização $C$: 0.1, 0.5, 1.0, 10, 100, 1000;\n",
    "\n",
    "Esperamos com todos esses fatores que nossa _baseline_ seja bastante robusta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV, RepeatedStratifiedKFold\n",
    "from sklearn.metrics import classification_report, plot_confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_80_20(df):\n",
    "    \"\"\"\n",
    "    Split Dataframe df into random train and test subsets. Using 80/20\n",
    "    division.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : DataFrame\n",
    "        Dataset to be splitted.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    X_train : DataFrame\n",
    "        Training dataset.\n",
    "    X_test : DataFrame\n",
    "        Testing dataset.\n",
    "    y_train : Series\n",
    "        Training targets.\n",
    "    y_test : Series\n",
    "        Testing targets.\n",
    "    \"\"\"\n",
    "    # Split dataset into features and target.\n",
    "    target_name = \"blue.win\"\n",
    "    target = df[target_name]\n",
    "    features = df.drop(target_name, 1)\n",
    "\n",
    "    # Split into train and test subsets.\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Training subset:"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(13017, 18)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(13017,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Testing subset:"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3255, 18)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(3255,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = split_80_20(blue_dataset)\n",
    "print(\"==> Training subset:\", end=\"\")\n",
    "display(X_train.shape, y_train.shape)\n",
    "print(\"==> Testing subset:\", end=\"\")\n",
    "display(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _define_baseline():\n",
    "    \"\"\"\n",
    "    Baseline model declaration.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    baseline : classifier object\n",
    "        Baseline it self.\n",
    "    \"\"\"\n",
    "    parameters = {'penalty': ['none', 'l2'], 'C': [0.1, 0.5, 1.0, 10, 100, 1000]}\n",
    "    lr = LogisticRegression(random_state=42)\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=4, random_state=42)\n",
    "    clf = GridSearchCV(lr, parameters, cv=cv)\n",
    "\n",
    "    return clf\n",
    "\n",
    "def _eval_model(\n",
    "        model, X_train, X_test, y_train, y_test,\n",
    "        params=False, digits_fmt=4):\n",
    "    \"\"\"\n",
    "    Displays evaluation metrics including classification report and\n",
    "    confusion matrix.\n",
    "    \n",
    "    If the argument 'params' is passed, will display a table of the \n",
    "    parameters hyperparameters used in the model.\n",
    "\n",
    "    This function is associated with `fit_and_evaluate()`. More \n",
    "    information see its description.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    digits_fmt : int\n",
    "        Number of digits for formatting output floating point values.\n",
    "    \"\"\"\n",
    "    # Get predictions.\n",
    "    y_predict_train = model.predict(X_train)\n",
    "    y_predict_test = model.predict(X_test)\n",
    "\n",
    "    # Classification report\n",
    "    print(\"=== CLASSIFICATION REPORT - TRAINING DATA ===\")\n",
    "    print(classification_report(y_train, y_predict_train, digits=digits_fmt))\n",
    "\n",
    "    print(\"=== CLASSIFICATION REPORT - TESTING DATA ===\")\n",
    "    print(classification_report(y_test, y_predict_test, digits=digits_fmt))\n",
    "\n",
    "    print(\"=== CONFUSION MATRIX ===\")\n",
    "    fig, ax = plt.subplots(figsize=(5,5))\n",
    "    plot_confusion_matrix(\n",
    "        model, X_test, y_test,\n",
    "        normalize=\"true\",\n",
    "        cmap=\"Purples\",\n",
    "        ax=ax)\n",
    "    ax.set_title(\"Confusion Matrix\")\n",
    "    plt.show()\n",
    "\n",
    "    if params:\n",
    "        print(\"=== MODEL PARAMETERS ===\")\n",
    "        params = pd.DataFrame(pd.Series(model.get_params()))\n",
    "        params.columns[\"parameters\"]\n",
    "        display(params)\n",
    "\n",
    "def fit_and_evaluate(model, X_train, X_test, y_train, y_test, params=False):\n",
    "    \"\"\"\n",
    "    Fits model on training data and displays classification evaluation metrics.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : classifier object\n",
    "        Type of classificatier model to use.\n",
    "    X_train : DataFrame\n",
    "        Training data with features variables.\n",
    "    X_test : DataFrame\n",
    "        Testing data with features variables.\n",
    "    y_train : Series\n",
    "        Training data with target variable.\n",
    "    y_test : Series\n",
    "        Testing data with target variable.\n",
    "    params : bool\n",
    "        Prints table of hyperparameters used in model.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    model : classifier object\n",
    "        Model after fitting on training data.\n",
    "    \"\"\"\n",
    "    model.fit(X_train, y_train)\n",
    "    _eval_model(model, X_train, X_test, y_train, y_test, params=params)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CLASSIFICATION REPORT - TRAINING DATA ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9780    0.9742    0.9761      6520\n",
      "           1     0.9742    0.9780    0.9761      6497\n",
      "\n",
      "    accuracy                         0.9761     13017\n",
      "   macro avg     0.9761    0.9761    0.9761     13017\n",
      "weighted avg     0.9761    0.9761    0.9761     13017\n",
      "\n",
      "=== CLASSIFICATION REPORT - TESTING DATA ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9816    0.9668    0.9741      1655\n",
      "           1     0.9662    0.9812    0.9736      1600\n",
      "\n",
      "    accuracy                         0.9739      3255\n",
      "   macro avg     0.9739    0.9740    0.9739      3255\n",
      "weighted avg     0.9740    0.9739    0.9739      3255\n",
      "\n",
      "=== CONFUSION MATRIX ===\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'AxesSubplot' object has no property 'figsize'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/lucas/Documentos/GitHub/ProjetoML/src/new_model.ipynb Cell 12\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/lucas/Documentos/GitHub/ProjetoML/src/new_model.ipynb#ch0000011?line=0'>1</a>\u001b[0m baseline \u001b[39m=\u001b[39m fit_and_evaluate(\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/lucas/Documentos/GitHub/ProjetoML/src/new_model.ipynb#ch0000011?line=1'>2</a>\u001b[0m     _define_baseline(), X_train, X_test, y_train, y_test)\n",
      "\u001b[1;32m/home/lucas/Documentos/GitHub/ProjetoML/src/new_model.ipynb Cell 12\u001b[0m in \u001b[0;36mfit_and_evaluate\u001b[0;34m(model, X_train, X_test, y_train, y_test, params)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/lucas/Documentos/GitHub/ProjetoML/src/new_model.ipynb#ch0000011?line=62'>63</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/lucas/Documentos/GitHub/ProjetoML/src/new_model.ipynb#ch0000011?line=63'>64</a>\u001b[0m \u001b[39mFits model on training data and displays classification evaluation metrics.\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/lucas/Documentos/GitHub/ProjetoML/src/new_model.ipynb#ch0000011?line=64'>65</a>\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/lucas/Documentos/GitHub/ProjetoML/src/new_model.ipynb#ch0000011?line=83'>84</a>\u001b[0m \u001b[39m    Model after fitting on training data.\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/lucas/Documentos/GitHub/ProjetoML/src/new_model.ipynb#ch0000011?line=84'>85</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/lucas/Documentos/GitHub/ProjetoML/src/new_model.ipynb#ch0000011?line=85'>86</a>\u001b[0m model\u001b[39m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/lucas/Documentos/GitHub/ProjetoML/src/new_model.ipynb#ch0000011?line=86'>87</a>\u001b[0m _eval_model(model, X_train, X_test, y_train, y_test, params\u001b[39m=\u001b[39;49mparams)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/lucas/Documentos/GitHub/ProjetoML/src/new_model.ipynb#ch0000011?line=88'>89</a>\u001b[0m \u001b[39mreturn\u001b[39;00m model\n",
      "\u001b[1;32m/home/lucas/Documentos/GitHub/ProjetoML/src/new_model.ipynb Cell 12\u001b[0m in \u001b[0;36m_eval_model\u001b[0;34m(model, X_train, X_test, y_train, y_test, params, digits_fmt)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/lucas/Documentos/GitHub/ProjetoML/src/new_model.ipynb#ch0000011?line=43'>44</a>\u001b[0m \u001b[39mprint\u001b[39m(classification_report(y_test, y_predict_test, digits\u001b[39m=\u001b[39mdigits_fmt))\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/lucas/Documentos/GitHub/ProjetoML/src/new_model.ipynb#ch0000011?line=45'>46</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m=== CONFUSION MATRIX ===\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/lucas/Documentos/GitHub/ProjetoML/src/new_model.ipynb#ch0000011?line=46'>47</a>\u001b[0m fig, ax \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39;49msubplot(figsize\u001b[39m=\u001b[39;49m(\u001b[39m5\u001b[39;49m,\u001b[39m5\u001b[39;49m))\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/lucas/Documentos/GitHub/ProjetoML/src/new_model.ipynb#ch0000011?line=47'>48</a>\u001b[0m plot_confusion_matrix(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/lucas/Documentos/GitHub/ProjetoML/src/new_model.ipynb#ch0000011?line=48'>49</a>\u001b[0m     model, X_test, y_test,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/lucas/Documentos/GitHub/ProjetoML/src/new_model.ipynb#ch0000011?line=49'>50</a>\u001b[0m     normalize\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtrue\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/lucas/Documentos/GitHub/ProjetoML/src/new_model.ipynb#ch0000011?line=50'>51</a>\u001b[0m     cmap\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPurples\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/lucas/Documentos/GitHub/ProjetoML/src/new_model.ipynb#ch0000011?line=51'>52</a>\u001b[0m     ax\u001b[39m=\u001b[39max)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/lucas/Documentos/GitHub/ProjetoML/src/new_model.ipynb#ch0000011?line=52'>53</a>\u001b[0m ax\u001b[39m.\u001b[39mset_title(\u001b[39m\"\u001b[39m\u001b[39mConfusion Matrix\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/matplotlib/pyplot.py:1283\u001b[0m, in \u001b[0;36msubplot\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1280\u001b[0m             \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m   1281\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1282\u001b[0m     \u001b[39m# we have exhausted the known Axes and none match, make a new one!\u001b[39;00m\n\u001b[0;32m-> 1283\u001b[0m     ax \u001b[39m=\u001b[39m fig\u001b[39m.\u001b[39;49madd_subplot(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1285\u001b[0m fig\u001b[39m.\u001b[39msca(ax)\n\u001b[1;32m   1287\u001b[0m bbox \u001b[39m=\u001b[39m ax\u001b[39m.\u001b[39mbbox\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/matplotlib/figure.py:772\u001b[0m, in \u001b[0;36mFigureBase.add_subplot\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    769\u001b[0m         args \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(\u001b[39mmap\u001b[39m(\u001b[39mint\u001b[39m, \u001b[39mstr\u001b[39m(args[\u001b[39m0\u001b[39m])))\n\u001b[1;32m    770\u001b[0m     projection_class, pkw \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_projection_requirements(\n\u001b[1;32m    771\u001b[0m         \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 772\u001b[0m     ax \u001b[39m=\u001b[39m subplot_class_factory(projection_class)(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mpkw)\n\u001b[1;32m    773\u001b[0m     key \u001b[39m=\u001b[39m (projection_class, pkw)\n\u001b[1;32m    774\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_add_axes_internal(ax, key)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/matplotlib/axes/_subplots.py:34\u001b[0m, in \u001b[0;36mSubplotBase.__init__\u001b[0;34m(self, fig, *args, **kwargs)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[39m----------\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[39m    Keyword arguments are passed to the Axes (sub)class constructor.\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[39m# _axes_class is set in the subplot_class_factory\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_axes_class\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\u001b[39mself\u001b[39;49m, fig, [\u001b[39m0\u001b[39;49m, \u001b[39m0\u001b[39;49m, \u001b[39m1\u001b[39;49m, \u001b[39m1\u001b[39;49m], \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     35\u001b[0m \u001b[39m# This will also update the axes position.\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_subplotspec(SubplotSpec\u001b[39m.\u001b[39m_from_subplot_args(fig, args))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/matplotlib/_api/deprecation.py:456\u001b[0m, in \u001b[0;36mmake_keyword_only.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m name_idx:\n\u001b[1;32m    451\u001b[0m     warn_deprecated(\n\u001b[1;32m    452\u001b[0m         since, message\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPassing the \u001b[39m\u001b[39m%(name)s\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m%(obj_type)s\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    453\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mpositionally is deprecated since Matplotlib \u001b[39m\u001b[39m%(since)s\u001b[39;00m\u001b[39m; the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    454\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mparameter will become keyword-only \u001b[39m\u001b[39m%(removal)s\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    455\u001b[0m         name\u001b[39m=\u001b[39mname, obj_type\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m()\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 456\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/matplotlib/axes/_base.py:646\u001b[0m, in \u001b[0;36m_AxesBase.__init__\u001b[0;34m(self, fig, rect, facecolor, frameon, sharex, sharey, label, xscale, yscale, box_aspect, **kwargs)\u001b[0m\n\u001b[1;32m    643\u001b[0m \u001b[39mif\u001b[39;00m yscale:\n\u001b[1;32m    644\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_yscale(yscale)\n\u001b[0;32m--> 646\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mupdate(kwargs)\n\u001b[1;32m    648\u001b[0m \u001b[39mfor\u001b[39;00m name, axis \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_axis_map()\u001b[39m.\u001b[39mitems():\n\u001b[1;32m    649\u001b[0m     axis\u001b[39m.\u001b[39mcallbacks\u001b[39m.\u001b[39m_pickled_cids\u001b[39m.\u001b[39madd(\n\u001b[1;32m    650\u001b[0m         axis\u001b[39m.\u001b[39mcallbacks\u001b[39m.\u001b[39mconnect(\n\u001b[1;32m    651\u001b[0m             \u001b[39m'\u001b[39m\u001b[39munits\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_unit_change_handler(name)))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/matplotlib/artist.py:1064\u001b[0m, in \u001b[0;36mArtist.update\u001b[0;34m(self, props)\u001b[0m\n\u001b[1;32m   1062\u001b[0m             func \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mset_\u001b[39m\u001b[39m{\u001b[39;00mk\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m   1063\u001b[0m             \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m callable(func):\n\u001b[0;32m-> 1064\u001b[0m                 \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m!r}\u001b[39;00m\u001b[39m object \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1065\u001b[0m                                      \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mhas no property \u001b[39m\u001b[39m{\u001b[39;00mk\u001b[39m!r}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1066\u001b[0m             ret\u001b[39m.\u001b[39mappend(func(v))\n\u001b[1;32m   1067\u001b[0m \u001b[39mif\u001b[39;00m ret:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'AxesSubplot' object has no property 'figsize'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "baseline = fit_and_evaluate(\n",
    "    _define_baseline(), X_train, X_test, y_train, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "112989f40982219f9c2133127490be09f86560db102a13a350eb86b01002b443"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
